{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'context_unet.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     18\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(m,         \u001b[38;5;66;03m# model being run \u001b[39;00m\n\u001b[0;32m     19\u001b[0m          (samples, t),       \u001b[38;5;66;03m# model input (or a tuple for multiple inputs) \u001b[39;00m\n\u001b[0;32m     20\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmymodel.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m,       \u001b[38;5;66;03m# where to save the model  \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m          output_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelOutput\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# the model's output names \u001b[39;00m\n\u001b[0;32m     26\u001b[0m ) \n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_unet.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m onnx\u001b[38;5;241m.\u001b[39mchecker\u001b[38;5;241m.\u001b[39mcheck_model(onnx_model)\n",
      "File \u001b[1;32md:\\bin\\miniforge3\\envs\\pytorch2\\Lib\\site-packages\\onnx\\__init__.py:210\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(f, format, load_external_data)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[0;32m    190\u001b[0m     f: IO[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike,\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mformat\u001b[39m: _SupportedFormat \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# noqa: A002\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     load_external_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelProto:\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a serialized ModelProto into memory.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m        Loaded in-memory ModelProto.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     model \u001b[38;5;241m=\u001b[39m _get_serializer(\u001b[38;5;28mformat\u001b[39m, f)\u001b[38;5;241m.\u001b[39mdeserialize_proto(\u001b[43m_load_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m, ModelProto())\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_external_data:\n\u001b[0;32m    213\u001b[0m         model_filepath \u001b[38;5;241m=\u001b[39m _get_file_path(f)\n",
      "File \u001b[1;32md:\\bin\\miniforge3\\envs\\pytorch2\\Lib\\site-packages\\onnx\\__init__.py:147\u001b[0m, in \u001b[0;36m_load_bytes\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     f \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], f)\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m readable:\n\u001b[0;32m    148\u001b[0m         content \u001b[38;5;241m=\u001b[39m readable\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'context_unet.onnx'"
     ]
    }
   ],
   "source": [
    "# export model to onnx format without weights and biases\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src') # to be able to import functions from src\n",
    "\n",
    "import torch\n",
    "from unet import *\n",
    "\n",
    "# network hyperparameters\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "n_cfeat = 5 # context vector is of size 5\n",
    "height = 16 # 16x16 image\n",
    "in_channels=3 # rgb\n",
    "\n",
    "m = ContextUnet(in_channels, n_feat=n_feat, n_cfeat=n_cfeat, height=height)\n",
    "samples = torch.randn(9, 3, height, height) \n",
    "t = torch.tensor([1 / 500])[:, None, None, None]\n",
    "torch.onnx.export(m,         # model being run \n",
    "         (samples, t),       # model input (or a tuple for multiple inputs) \n",
    "         \"mymodel.onnx\",       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         opset_version=10,    # the ONNX version to export the model to \n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "         input_names = ['samples', 'timestamp'],   # the model's input names \n",
    "         output_names = ['modelOutput'], # the model's output names \n",
    ") \n",
    "\n",
    "import onnx\n",
    "onnx_model = onnx.load(\"mymodel.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
